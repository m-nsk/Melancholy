{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Hanqi-Xiao\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.16</td>\n",
       "      <td>0.687</td>\n",
       "      <td>0.154</td>\n",
       "      <td>-0.3712</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    neg    neu    pos  compound\n",
       "0  0.16  0.687  0.154   -0.3712"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Text</th>\n",
       "      <th>Word Cloud Text</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Word Cloud Frequency</th>\n",
       "      <th>Word Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-03-06</td>\n",
       "      <td>March 6, 2012\\n\\nDear Diary,\\n\\nSorry I didn’t...</td>\n",
       "      <td>[March, 6, 2012, Dear, Diary, Sorry, I, get, w...</td>\n",
       "      <td>neg    neu    pos  compound\n",
       "0  0.16  0.687...</td>\n",
       "      <td>{'March': 1, '6': 1, '2012': 1, 'Dear': 1, 'Di...</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date                                               Text  \\\n",
       "0  2012-03-06  March 6, 2012\\n\\nDear Diary,\\n\\nSorry I didn’t...   \n",
       "\n",
       "                                     Word Cloud Text  \\\n",
       "0  [March, 6, 2012, Dear, Diary, Sorry, I, get, w...   \n",
       "\n",
       "                                           Sentiment  \\\n",
       "0      neg    neu    pos  compound\n",
       "0  0.16  0.687...   \n",
       "\n",
       "                                Word Cloud Frequency Word Count  \n",
       "0  {'March': 1, '6': 1, '2012': 1, 'Dear': 1, 'Di...        110  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.099</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.161</td>\n",
       "      <td>0.977</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     neg   neu    pos  compound\n",
       "0  0.099  0.74  0.161     0.977"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Text</th>\n",
       "      <th>Word Cloud Text</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Word Cloud Frequency</th>\n",
       "      <th>Word Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-03-04</td>\n",
       "      <td>March 4, 2012\\n\\nDear Diary,\\n\\nToday was a li...</td>\n",
       "      <td>[March, 4, 2012, Dear, Diary, Today, little, b...</td>\n",
       "      <td>neg   neu    pos  compound\n",
       "0  0.099  0.74...</td>\n",
       "      <td>{'March': 1, '4': 1, '2012': 1, 'Dear': 1, 'Di...</td>\n",
       "      <td>204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-03-06</td>\n",
       "      <td>March 6, 2012\\n\\nDear Diary,\\n\\nSorry I didn’t...</td>\n",
       "      <td>[March, 6, 2012, Dear, Diary, Sorry, I, get, w...</td>\n",
       "      <td>neg    neu    pos  compound\n",
       "0  0.16  0.687...</td>\n",
       "      <td>{'March': 1, '6': 1, '2012': 1, 'Dear': 1, 'Di...</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date                                               Text  \\\n",
       "0  2012-03-04  March 4, 2012\\n\\nDear Diary,\\n\\nToday was a li...   \n",
       "0  2012-03-06  March 6, 2012\\n\\nDear Diary,\\n\\nSorry I didn’t...   \n",
       "\n",
       "                                     Word Cloud Text  \\\n",
       "0  [March, 4, 2012, Dear, Diary, Today, little, b...   \n",
       "0  [March, 6, 2012, Dear, Diary, Sorry, I, get, w...   \n",
       "\n",
       "                                           Sentiment  \\\n",
       "0       neg   neu    pos  compound\n",
       "0  0.099  0.74...   \n",
       "0      neg    neu    pos  compound\n",
       "0  0.16  0.687...   \n",
       "\n",
       "                                Word Cloud Frequency Word Count  \n",
       "0  {'March': 1, '4': 1, '2012': 1, 'Dear': 1, 'Di...        204  \n",
       "0  {'March': 1, '6': 1, '2012': 1, 'Dear': 1, 'Di...        110  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n"
     ]
    }
   ],
   "source": [
    "\"\"\"A NLP based Diary. Two\"\"\"\n",
    "# Capturing settings.\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "from textblob import TextBlob\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import pos_tag\n",
    "from matplotlib import pyplot as plt\n",
    "from textblob import Word\n",
    "from get_txt import fetch\n",
    "import string\n",
    "import nltk\n",
    "from wordcloud import WordCloud\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from transformers import pipeline\n",
    "\n",
    "\n",
    "def filter_insignificant(chunk, tag_suffixes=['DT', 'CC']):\n",
    "  good = []\n",
    "\n",
    "  for word, tag in chunk:\n",
    "    ok = True\n",
    "\n",
    "    for suffix in tag_suffixes:\n",
    "      if tag.endswith(suffix):\n",
    "        ok = False\n",
    "        break\n",
    "\n",
    "    if ok:\n",
    "      good.append((word, tag))\n",
    "\n",
    "  return good\n",
    "\n",
    "\n",
    "def word_frequencies(cloud_cleaned_entry: list[str]) -> dict[str, int]:\n",
    "    freq_dict = dict()\n",
    "    for word in cloud_cleaned_entry:\n",
    "        if word not in freq_dict:\n",
    "            freq_dict[word] = 1\n",
    "        else:\n",
    "            freq_dict[word] += 1\n",
    "    # print(\"\\n\".join([f\"{word} : {freq}\" for word, freq in freq_dict.items()]))\n",
    "    return freq_dict\n",
    "\n",
    "\n",
    "def word_cloud_clean(entry: str) -> str:\n",
    "    \"\"\"Clean every paragraph, stems all the words, puts into one list.\"\"\"\n",
    "    stemmer = PorterStemmer()\n",
    "    eng_stops: list[str] = stopwords.words(\"english\")\n",
    "    entry = [i for i in word_tokenize(entry) if i not in eng_stops]\n",
    "    entry = list(filter(lambda word: word not in string.punctuation+\"’“”\", entry))\n",
    "    entry = [word for word, pos in filter_insignificant(pos_tag(entry))]\n",
    "    # print(entry)\n",
    "    # entry = [stemmer.stem(w) for w in entry]\n",
    "    return entry\n",
    "\n",
    "\n",
    "def sentiment_polarity(entry: str) -> float:\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    sentiment = analyzer.polarity_scores(entry)\n",
    "    sentiment = pd.json_normalize(sentiment)\n",
    "    display(sentiment)\n",
    "    print(type(sentiment))\n",
    "    return sentiment\n",
    "\n",
    "\n",
    "def emotion_polarity(entry: str) -> float:\n",
    "    \"\"\"Polarity determine.\"\"\"\n",
    "    classifier = pipeline(\"text-classification\", model = \"bhadresh-savani/distilbert-base-uncased-emotion\")\n",
    "    # classifier = pipeline(\"sentiment-analysis\")\n",
    "    predict = classifier(entry)\n",
    "    print(predict)\n",
    "    return predict\n",
    "\n",
    "\n",
    "class MelanJournal():\n",
    "    reminder_time: datetime\n",
    "    new_user: bool = True\n",
    "    data: pd.DataFrame\n",
    "\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Runs upon restarting the program.\"\"\"\n",
    "        if self.new_user == True:\n",
    "            self.settings()\n",
    "            self.new_user = False\n",
    "            self.data = pd.DataFrame(columns = [\"Date\", \"Text\", \"Word Cloud Text\", \"Sentiment\", \"Word Cloud Frequency\", \"Word Count\"])\n",
    "\n",
    "\n",
    "    def settings(self) -> None:\n",
    "        \"\"\"Sets or changes the settings.\"\"\"\n",
    "        # reminder_time = input(\"In the format HH:MM: \")\n",
    "        reminder_time = \"03:35\"\n",
    "        self.reminder_time = datetime.time(*map(int, reminder_time.split(':')))\n",
    "\n",
    "\n",
    "    def turn_into_data_frame(self, data: dict[str, str]) -> None:\n",
    "        \"\"\"Convert into a dataframe.\"\"\"\n",
    "        print(type(data))\n",
    "        word_cloud_text = word_cloud_clean(data[\"Text\"])\n",
    "        sentiment = sentiment_polarity(data[\"Text\"])\n",
    "        word_cloud_frequency = word_frequencies(word_cloud_text)\n",
    "        word_count = len(word_cloud_text)\n",
    "        data[\"Word Cloud Text\"] = word_cloud_text\n",
    "        data[\"Sentiment\"] = sentiment\n",
    "        data[\"Word Cloud Frequency\"] = word_cloud_frequency\n",
    "        data[\"Word Count\"] = word_count\n",
    "\n",
    "        self.data = pd.concat([pd.DataFrame([data]), self.data], sort = False)\n",
    "        # # Calculate all variables.\n",
    "        # self.data[\"Word Cloud Text\"] = self.data[\"Text\"].apply(word_cloud_clean)\n",
    "        # # self.data[\"Emotions\"] = self.data[\"Text\"].apply(emotion_polarity)\n",
    "        # self.data[\"Sentiment\"] = self.data[\"Text\"].apply(sentiment_polarity)\n",
    "        # print(type(self.data[\"Sentiment\"][0]))\n",
    "        # self.data[\"Word Cloud Frequency\"] = self.data[\"Word Cloud Text\"].apply(word_frequencies)\n",
    "        # self.data[\"Word Count\"] = self.data[\"Word Cloud Text\"].apply(lambda x: len(x))\n",
    "\n",
    "        display(self.data)\n",
    "\n",
    "    \n",
    "    def wordcloud(self) -> None:\n",
    "        for i, row in self.data.iterrows():\n",
    "            frequencies = row[\"Word Cloud Frequency\"]\n",
    "            cloud = WordCloud(background_color=\"White\")\n",
    "            cloud.generate_from_frequencies(frequencies)\n",
    "            plt.figure(figsize=(20,5), )\n",
    "            plt.imshow(cloud, interpolation=\"bilinear\")\n",
    "            plt.axis(\"off\")\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "    def plotmy_stuffies(self) -> None:\n",
    "        \"\"\"Deprecated\"\"\"\n",
    "        sentiments = self.data[\"Sentiment\"]\n",
    "        print(type(sentiments))\n",
    "\n",
    "\n",
    "    def sentiment_by_time(self) -> None:\n",
    "        \"\"\"Make a new column where a new column is added to the dataframe.\"\"\"\n",
    "        sentiments = self.data[\"Sentiment\"]\n",
    "        datings = self.data[\"Date\"]\n",
    "        print(type(sentiments))\n",
    "        heights = []\n",
    "        for i, frame in sentiments.items():\n",
    "            print(type(frame[\"compound\"][0]))\n",
    "            heights.append(frame[\"compound\"][0])\n",
    "        for i, frame in datings.items():\n",
    "            print(type(frame[\"Date\"][0]))\n",
    "            heights.append(frame[\"Date\"][0])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def main() -> None:\n",
    "    journal = MelanJournal()\n",
    "    journal.turn_into_data_frame(fetch(\"sample_3.txt\"))\n",
    "    journal.turn_into_data_frame(fetch(\"sample_2.txt\"))\n",
    "    # journal.wordcloud()\n",
    "    journal.sentiment_by_time()\n",
    "    pass\n",
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "14301f198264045c185a24a22454107cc10220100870000c1930fb2c9380cc74"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
